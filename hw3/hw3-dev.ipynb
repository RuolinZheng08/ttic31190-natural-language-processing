{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        lines: [['hello', 'world'], ...]\n",
    "        labels: [[!], [N], ...]\n",
    "        vocab\n",
    "    \"\"\"\n",
    "    with open(file, 'rt') as f:\n",
    "        text = f.read()\n",
    "    lines = text.split('\\n\\n')\n",
    "    ret_lines = []\n",
    "    labels = []\n",
    "    vocab = set()\n",
    "    for line in lines:\n",
    "        if not line: \n",
    "            continue\n",
    "        curr_line = []\n",
    "        for token_label_str in line.split('\\n'):\n",
    "            if not token_label_str: \n",
    "                continue\n",
    "            token, label = token_label_str.split('\\t')\n",
    "            vocab.add(token)\n",
    "            labels.append(label)\n",
    "            curr_line.append(token)\n",
    "        ret_lines.append(curr_line)\n",
    "    return ret_lines, labels, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lines(lines, word2idx_map, window_size):\n",
    "    \"\"\"\n",
    "    returns X: len(lines) x (2 * window_size + 1)\n",
    "    \"\"\"\n",
    "    def encode_line(line, word2idx_map, window_size):\n",
    "        num_repr = [] # numerical representation\n",
    "        for word in line:\n",
    "            num = word2idx_map.get(word, word2idx_map['UUUNKKK'])\n",
    "            num_repr.append(num)\n",
    "        # pad with start and end tokens\n",
    "        start = [word2idx_map['<s>']] * window_size\n",
    "        end = [word2idx_map['</s>']] * window_size\n",
    "        padded = start + num_repr + end\n",
    "        \n",
    "        ret = []\n",
    "        for i in range(window_size, len(padded) - window_size):\n",
    "            windowed = padded[i - window_size : i + window_size + 1]\n",
    "            ret.append(windowed)\n",
    "            \n",
    "        return ret\n",
    "    \n",
    "    res = []\n",
    "    for line in lines:\n",
    "        res.extend(encode_line(line, word2idx_map, window_size))\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, window_size, output_dim,\n",
    "                 emb_dim=50, pretrained_emb=None, freeze=False):\n",
    "        super(FeedForwardTagger, self).__init__()\n",
    "        if pretrained_emb:\n",
    "            self.emb = nn.Embedding.from_pretrained(pretrain_emb)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "            torch.nn.init.uniform_(self.emb.weight, -0.01, 0.01)\n",
    "        input_dim = (2 * window_size + 1) * emb_dim\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.emb(inputs).view((inputs.shape[0], -1))\n",
    "        out = F.tanh(self.fc1(embeds))\n",
    "        out = self.fc2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_util(model, X_train, Y_train, X_dev, Y_dev, n_epochs, lr, \n",
    "              batch_size):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_model = None\n",
    "    losses = []\n",
    "    train_accu_list, dev_accu_list = [], []\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            log_probs = model(X_train[i : i + batch_size])\n",
    "            loss = loss_func(log_probs, Y_train[i : i + batch_size])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_preds = torch.argmax(model(X_train), dim=1)\n",
    "        train_accu = accuracy_score(Y_train, train_preds)\n",
    "        # evaluate on dev\n",
    "        dev_preds = torch.argmax(model(X_dev), dim=1)\n",
    "        dev_accu = accuracy_score(Y_dev, dev_preds)\n",
    "        \n",
    "        print(epoch, epoch_loss, train_accu, dev_accu)\n",
    "        losses.append(epoch_loss)\n",
    "        train_accu_list.append(train_accu)\n",
    "        dev_accu_list.append(dev_accu)\n",
    "        \n",
    "    return losses, train_accu_list, dev_accu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels, train_vocab = read_corpus(DATADIR + 'twpos-train.tsv')\n",
    "dev, dev_labels, dev_vocab = read_corpus(DATADIR + 'twpos-dev.tsv')\n",
    "devtest, devtest_labels, devtest_vocab = read_corpus(DATADIR + 'twpos-devtest.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(list(set(train_labels)))\n",
    "Y_train = label_encoder.transform(train_labels)\n",
    "Y_dev = label_encoder.transform(dev_labels)\n",
    "Y_devtest = label_encoder.transform(devtest_labels)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_dev = torch.tensor(Y_dev, dtype=torch.long)\n",
    "Y_devtest = torch.tensor(Y_devtest, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_vocab.copy()\n",
    "vocab.update(dev_vocab)\n",
    "vocab.update(devtest_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baseline w/ Randomly Initialized Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct maps for randomly initialized embs\n",
    "idx2word_rand = sorted(vocab)\n",
    "idx2word_rand += ['<s>', '</s>', 'UUUNKKK']\n",
    "word2idx_rand = {word: idx for idx, word in enumerate(idx2word_rand)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Train, Dev, DevTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 0\n",
    "X_train_w0 = encode_lines(train, word2idx_rand, window_size=0)\n",
    "X_dev_w0 = encode_lines(dev, word2idx_rand, window_size=0)\n",
    "X_devtest_w0 = encode_lines(devtest, word2idx_rand, window_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 1\n",
    "X_train_w1 = encode_lines(train, word2idx_rand, window_size=1)\n",
    "X_dev_w1 = encode_lines(dev, word2idx_rand, window_size=1)\n",
    "X_devtest_w1 = encode_lines(devtest, word2idx_rand, window_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26318.854907561443 0.6308231173380034 0.6191661481020535\n",
      "1 19847.687172139587 0.6945709281961471 0.6672889442024477\n",
      "2 17140.754573532566 0.7364273204903677 0.6913503422526447\n",
      "3 15147.710087355106 0.7639813193228254 0.705247873885086\n",
      "4 13384.72553572192 0.7875656742556918 0.7118855009334163\n",
      "5 11717.211856766744 0.8145942790426153 0.7251607550300767\n",
      "6 10178.92038353162 0.8334500875656743 0.7334577888404895\n",
      "7 8734.392380004963 0.8512551079976649 0.7373988799004356\n",
      "8 7502.108096102407 0.8659077641564507 0.7440365069487658\n",
      "9 6518.994200649857 0.8785755983654407 0.7463181912466293\n",
      "10 5772.929299781988 0.8897256275539989 0.7498444306160548\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-d1bd19d2ceb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                           \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           output_dim=len(all_labels))\n\u001b[0;32m----> 4\u001b[0;31m _ = train_util(model, X_train_w0, Y_train, X_dev_w0, Y_dev, n_epochs=50,\n\u001b[0m\u001b[1;32m      5\u001b[0m               lr=0.02, batch_size=1)\n",
      "\u001b[0;32m<ipython-input-153-bd695acbdb5d>\u001b[0m in \u001b[0;36mtrain_util\u001b[0;34m(model, X_train, Y_train, X_dev, Y_dev, n_epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ruolinzheng/conda/envs/py38/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ruolinzheng/conda/envs/py38/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0maccumulate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0minto\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \"\"\"\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"retains_grad\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"\n\u001b[1;32m    735\u001b[0m                           \u001b[0;34m\"attribute won't be populated during autograd.backward(). If you indeed want the gradient \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = FeedForwardTagger(vocab_size=len(word2idx_rand), \n",
    "                          window_size=0,\n",
    "                          output_dim=len(all_labels))\n",
    "_ = train_util(model, X_train_w0, Y_train, X_dev_w0, Y_dev, n_epochs=50,\n",
    "              lr=0.02, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 37.45856440067291 0.47542323409223586 0.4665007259904584\n",
      "1 28.97168219089508 0.5270286047869235 0.5179423356150177\n",
      "2 26.855947971343994 0.553298307063631 0.5390997718315702\n",
      "3 25.546590089797974 0.5666666666666667 0.5471893797967227\n",
      "4 24.535447239875793 0.5816112084063048 0.5648205766438498\n",
      "5 23.65640115737915 0.5928196147110333 0.5770587015142087\n",
      "6 22.863015830516815 0.6021599532983071 0.587637419622485\n",
      "7 22.13068777322769 0.6159369527145359 0.6015349512549264\n",
      "8 21.44322830438614 0.626444833625219 0.6100394109105994\n",
      "9 20.789773643016815 0.6359603035610041 0.6183364447210122\n",
      "10 20.163319408893585 0.6489784004670169 0.6295374403650695\n",
      "11 19.56081885099411 0.6612375948628137 0.6448869529143332\n",
      "12 18.982388079166412 0.6704611792177466 0.6511097282721428\n",
      "13 18.42963135242462 0.6810858143607705 0.6575399294752126\n",
      "14 17.904225826263428 0.6890251021599533 0.6637627048330222\n",
      "15 17.407002925872803 0.6974314068884997 0.6699854801908318\n",
      "16 16.93762093782425 0.7078225335668418 0.6747562746318191\n",
      "17 16.494434893131256 0.7139521307647402 0.6774528106202032\n",
      "18 16.0740886926651 0.7235843549328663 0.6826384567517113\n",
      "19 15.671242237091064 0.7294220665499125 0.6849201410495748\n",
      "20 15.28036281466484 0.7361354349095155 0.6878241028832193\n",
      "21 14.898711413145065 0.7437828371278459 0.6919726197884256\n",
      "22 14.526687383651733 0.7506713368359603 0.6977805434557146\n",
      "23 14.165237337350845 0.7562171628721541 0.7023439120514416\n",
      "24 13.814095467329025 0.7611792177466433 0.7044181705040448\n",
      "25 13.472630947828293 0.7663747810858144 0.7073221323376893\n",
      "26 13.14066657423973 0.772913018096906 0.7104335200165941\n",
      "27 12.817611992359161 0.7781669585522475 0.7137523335407592\n",
      "28 12.502139911055565 0.7829538820782254 0.7164488695291433\n",
      "29 12.192316085100174 0.7880910683012259 0.7197676830533084\n",
      "30 11.887156203389168 0.7936952714535902 0.7222567931964323\n",
      "31 11.586382985115051 0.7994746059544658 0.7251607550300767\n",
      "32 11.289362370967865 0.8046701692936369 0.7286869943995021\n",
      "33 10.996020510792732 0.8094570928196148 0.7309686786973657\n",
      "34 10.707062810659409 0.8129597197898424 0.7324206596141879\n",
      "35 10.423526242375374 0.8185639229422067 0.7369840282099149\n",
      "36 10.14642533659935 0.8229422066549913 0.7365691765193944\n",
      "37 9.876470118761063 0.8287799182720373 0.7390582866625182\n",
      "38 9.613991260528564 0.833041447752481 0.7403028417340801\n",
      "39 9.358951926231384 0.8374197314652656 0.7432068035677245\n",
      "40 9.111110508441925 0.8417980151780502 0.7440365069487658\n",
      "41 8.870140478014946 0.8456509048453006 0.7452810620203277\n",
      "42 8.635758563876152 0.8491535318155283 0.7467330429371499\n",
      "43 8.407723426818848 0.8532399299474606 0.7479775980087119\n",
      "44 8.185895666480064 0.8571511967308815 0.7494295789255341\n",
      "45 7.9702055007219315 0.8615294804436661 0.751296411532877\n",
      "46 7.760665789246559 0.8634559252772913 0.7510889856876167\n",
      "47 7.5573408752679825 0.8669001751313485 0.751918689068658\n",
      "48 7.360313057899475 0.8700525394045534 0.7535780958307405\n",
      "49 7.169681400060654 0.8731465265615879 0.7539929475212611\n",
      "50 6.985536530613899 0.8757151196730881 0.7548226509023024\n",
      "51 6.807925328612328 0.8784588441330998 0.7550300767475627\n",
      "52 6.636857554316521 0.8817279626386456 0.7556523542833437\n",
      "53 6.472310960292816 0.8835960303561005 0.7562746318191247\n",
      "54 6.314241334795952 0.8855808523058961 0.757104335200166\n",
      "55 6.162565350532532 0.8886748394629306 0.7589711678075088\n",
      "56 6.0171960443258286 0.891009924109749 0.7591785936527692\n",
      "57 5.8780064433813095 0.8933450087565674 0.7591785936527692\n",
      "58 5.744866847991943 0.8957968476357268 0.7595934453432898\n",
      "59 5.617618218064308 0.8979568009340338 0.760423148724331\n",
      "60 5.496095582842827 0.9004086398131932 0.7608380004148517\n",
      "61 5.380121126770973 0.9018680677174548 0.761045426260112\n",
      "62 5.2695037722587585 0.9032691185055458 0.7612528521053723\n",
      "63 5.164051406085491 0.9052539404553415 0.7614602779506326\n",
      "64 5.063568651676178 0.9069468768242849 0.7618751296411533\n",
      "65 4.96784944832325 0.908231173380035 0.7620825554864136\n",
      "66 4.876695781946182 0.9095738470519557 0.7620825554864136\n",
      "67 4.789912082254887 0.9112667834208991 0.7620825554864136\n",
      "68 4.707295291125774 0.9123759486281378 0.7620825554864136\n",
      "69 4.628659792244434 0.9132516053706947 0.7612528521053723\n",
      "70 4.553818807005882 0.9142440163455925 0.7602157228790707\n",
      "71 4.482593588531017 0.9154115586690017 0.7606305745695914\n",
      "72 4.414814226329327 0.9162288382953883 0.7606305745695914\n",
      "73 4.350320838391781 0.9171044950379451 0.7608380004148517\n",
      "74 4.288955330848694 0.9178633975481612 0.7606305745695914\n",
      "75 4.230572491884232 0.9190893169877408 0.7612528521053723\n",
      "76 4.175033517181873 0.9198482194979568 0.761045426260112\n",
      "77 4.122199960052967 0.9206071220081729 0.7612528521053723\n",
      "78 4.071947202086449 0.9214244016345593 0.761045426260112\n",
      "79 4.024157628417015 0.9222416812609457 0.7606305745695914\n",
      "80 3.978716790676117 0.9228254524226503 0.7608380004148517\n",
      "81 3.935517244040966 0.9235259778166959 0.761045426260112\n",
      "82 3.894454389810562 0.9241681260945709 0.7614602779506326\n",
      "83 3.8554341718554497 0.9246935201401051 0.7612528521053723\n",
      "84 3.818358786404133 0.9248686514886164 0.7612528521053723\n",
      "85 3.783139482140541 0.9253940455341506 0.761667703795893\n",
      "86 3.7496866807341576 0.9258610624635143 0.7612528521053723\n",
      "87 3.71791572868824 0.926328079392878 0.7612528521053723\n",
      "88 3.687741719186306 0.9265032107413894 0.761045426260112\n",
      "89 3.6590830460190773 0.9266783420899007 0.761045426260112\n",
      "90 3.63186464458704 0.9268534734384122 0.761045426260112\n",
      "91 3.606009528040886 0.927086981903094 0.7612528521053723\n",
      "92 3.581445500254631 0.9271453590192644 0.761667703795893\n",
      "93 3.5580999925732613 0.9273788674839463 0.7618751296411533\n",
      "94 3.5359122306108475 0.9273788674839463 0.761667703795893\n",
      "95 3.5148127526044846 0.9276123759486281 0.761667703795893\n",
      "96 3.4947433471679688 0.927729130180969 0.7614602779506326\n",
      "97 3.475643679499626 0.92784588441331 0.7612528521053723\n",
      "98 3.4574602618813515 0.9279626386456509 0.7614602779506326\n",
      "99 3.4401411190629005 0.9279626386456509 0.7614602779506326\n"
     ]
    }
   ],
   "source": [
    "model = FeedForwardTagger(vocab_size=len(word2idx_rand), \n",
    "                          window_size=0,\n",
    "                          output_dim=len(all_labels))\n",
    "_ = train_util(model, X_train_w0, Y_train, X_dev_w0, Y_dev, n_epochs=100,\n",
    "              lr=2, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51.440529108047485 0.19573847051955634 0.194150591163659\n",
      "1 48.023465394973755 0.2266199649737303 0.2175897116780751\n",
      "2 46.34287214279175 0.35288966725043786 0.342874922215308\n",
      "3 41.87749195098877 0.4299474605954466 0.42086704003318814\n",
      "4 35.92560696601868 0.5002335084646818 0.49118440157643645\n",
      "5 30.338786840438843 0.5723876240513719 0.562331466500726\n",
      "6 26.115234375 0.6063631056625802 0.5924082140634723\n",
      "7 23.78149378299713 0.6359019264448337 0.6243517942335615\n",
      "8 22.21266460418701 0.6507880910683013 0.6357602157228791\n",
      "9 20.879288971424103 0.6665499124343257 0.6486206181290188\n",
      "10 19.59943276643753 0.6854640980735551 0.6635552789877619\n",
      "11 18.327219784259796 0.7091068301225919 0.685749844430616\n",
      "12 17.091582477092743 0.7260945709281962 0.6986102468367559\n",
      "13 15.919070184230804 0.7434909515469936 0.7164488695291433\n",
      "14 14.836877554655075 0.7580268534734385 0.7241236258037751\n",
      "15 13.847228109836578 0.773029772329247 0.7332503629952292\n",
      "16 12.93113088607788 0.7892586106246351 0.7446587844845468\n",
      "17 12.074517220258713 0.8065382370110916 0.7535780958307405\n",
      "18 11.270532697439194 0.8208406304728546 0.7595934453432898\n",
      "19 10.516156435012817 0.8333333333333334 0.76623107239162\n",
      "20 9.80966730415821 0.8454757734967893 0.7710018668326073\n",
      "21 9.149632915854454 0.8556333917104495 0.7722464219041693\n",
      "22 8.53471925854683 0.867717454757735 0.7747355320472931\n",
      "23 7.963774740695953 0.8785172212492703 0.7819954366314043\n",
      "24 7.435891419649124 0.8882078225335669 0.7851068243103091\n",
      "25 6.950159460306168 0.8964389959136019 0.790292470441817\n",
      "26 6.505162984132767 0.9032691185055458 0.7934038581207219\n",
      "27 6.098558910191059 0.9096322241681261 0.796100394109106\n",
      "28 5.727133437991142 0.914944541739638 0.8004563368595727\n",
      "29 5.387212730944157 0.9213660245183888 0.80522713130056\n",
      "30 5.075226470828056 0.9271453590192644 0.8079236672889442\n",
      "31 4.788108617067337 0.9326911850554582 0.8079236672889442\n",
      "32 4.523386672139168 0.9378867483946293 0.8093756482057665\n",
      "33 4.279067359864712 0.9408056042031524 0.8095830740510268\n",
      "34 4.053473729640245 0.9457676590776416 0.8151835718730553\n",
      "35 3.8451138101518154 0.9490367775831874 0.8180875337066998\n",
      "36 3.652587376534939 0.9516637478108582 0.8182949595519602\n",
      "37 3.4745282605290413 0.9544658493870403 0.8191246629330015\n",
      "38 3.309581145644188 0.9569760653823701 0.8189172370877411\n",
      "39 3.156458392739296 0.9590192644483363 0.8189172370877411\n",
      "40 3.0139965377748013 0.962405137186223 0.8201617921593031\n",
      "41 2.881157476454973 0.9642148277875073 0.8199543663140427\n",
      "42 2.7570230960845947 0.9669585522475189 0.8201617921593031\n",
      "43 2.640779733657837 0.9685347343841214 0.8201617921593031\n",
      "44 2.5317125283181667 0.969994162288383 0.820784069695084\n",
      "45 2.4291951432824135 0.9712200817279626 0.8211989213856047\n",
      "46 2.3326763473451138 0.9726795096322242 0.8211989213856047\n",
      "47 2.2416659239679575 0.9745475773496789 0.820784069695084\n",
      "48 2.155729304999113 0.9757151196730881 0.8205766438498237\n",
      "49 2.0744758751243353 0.9768826619964974 0.8205766438498237\n",
      "50 1.9975676201283932 0.978225335668418 0.8197469404687824\n",
      "51 1.9247102625668049 0.978984238178634 0.8197469404687824\n",
      "52 1.8556356467306614 0.9802101576182136 0.8197469404687824\n",
      "53 1.790073610842228 0.9808523058960887 0.819539514623522\n",
      "54 1.7277528699487448 0.9817863397548161 0.8182949595519602\n",
      "55 1.6684297509491444 0.9824868651488616 0.8178801078614395\n",
      "56 1.611886927857995 0.9829538820782253 0.8176726820161793\n",
      "57 1.557931363582611 0.983420899007589 0.816220701099357\n",
      "58 1.5063904635608196 0.9837127845884414 0.8153909977183157\n",
      "59 1.4571134457364678 0.9845300642148278 0.8149761460277951\n",
      "60 1.4099684488028288 0.984938704028021 0.8135241651109728\n",
      "61 1.3648386681452394 0.9853473438412143 0.8133167392657125\n",
      "62 1.3216189984232187 0.9857559836544074 0.8126944617299315\n",
      "63 1.2802110770717263 0.9862230005837712 0.8131093134204522\n",
      "64 1.24052404332906 0.986573263280794 0.8131093134204522\n",
      "65 1.2024719985201955 0.9868067717454758 0.8131093134204522\n",
      "66 1.1659759748727083 0.987215411558669 0.8124870358846712\n",
      "67 1.1309627071022987 0.9877408056042032 0.8120721841941506\n",
      "68 1.0973648987710476 0.9883245767659078 0.8112424808131093\n",
      "69 1.0651192730292678 0.9885580852305896 0.8102053515868077\n",
      "70 1.0341662783175707 0.9890834792761237 0.8102053515868077\n",
      "71 1.0044486820697784 0.989492119089317 0.809790499896287\n",
      "72 0.9759108256548643 0.9904261529480444 0.809790499896287\n",
      "73 0.948500495404005 0.990893169877408 0.8091682223605061\n",
      "74 0.9221660643815994 0.9915353181552832 0.8087533706699854\n",
      "75 0.8968579489737749 0.9918272037361354 0.8081310931342045\n",
      "76 0.8725293232128024 0.9921190893169878 0.8081310931342045\n",
      "77 0.8491353504359722 0.9922358435493287 0.8077162414436839\n",
      "78 0.8266343222931027 0.9925861062463515 0.8070939639079029\n",
      "79 0.8049868401139975 0.9931698774080561 0.8062642605268616\n",
      "80 0.7841558670625091 0.9935785172212492 0.805849408836341\n",
      "81 0.7641062559559941 0.9935201401050788 0.805849408836341\n",
      "82 0.7448059758171439 0.9938704028021016 0.8060568346816013\n",
      "83 0.72622459102422 0.9942790426152948 0.805849408836341\n",
      "84 0.708333199378103 0.9944541739638062 0.805849408836341\n",
      "85 0.6911049555055797 0.9945709281961471 0.80522713130056\n",
      "86 0.6745138736441731 0.9946293053123175 0.8050197054552998\n",
      "87 0.6585360825993121 0.9947460595446584 0.8050197054552998\n",
      "88 0.6431480688042939 0.9947460595446584 0.80522713130056\n",
      "89 0.6283268029801548 0.994804436660829 0.8050197054552998\n",
      "90 0.6140503622591496 0.9950963222416812 0.8048122796100394\n",
      "91 0.6002967106178403 0.9952130764740221 0.8048122796100394\n",
      "92 0.5870445100590587 0.9953298307063632 0.8041900020742585\n",
      "93 0.5742720784619451 0.9953882078225336 0.8037751503837378\n",
      "94 0.5619586114771664 0.995563339171045 0.8031528728479569\n",
      "95 0.5500829494558275 0.9957384705195563 0.8029454470026965\n",
      "96 0.5386254792101681 0.9957968476357268 0.8029454470026965\n",
      "97 0.5275667607784271 0.9957968476357268 0.8033602986932171\n",
      "98 0.5168875684030354 0.9959136018680678 0.8027380211574362\n",
      "99 0.506570574361831 0.99620548744892 0.8027380211574362\n"
     ]
    }
   ],
   "source": [
    "model = FeedForwardTagger(vocab_size=len(word2idx_rand), \n",
    "                          window_size=1,\n",
    "                          output_dim=len(all_labels))\n",
    "_ = train_util(model, X_train_w1, Y_train, X_dev_w1, Y_dev, n_epochs=100,\n",
    "              lr=1, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36.602572202682495 0.5162288382953882 0.5131715411740303\n",
      "1 26.249264121055603 0.5722124927028605 0.5517527483924497\n",
      "2 23.507112979888916 0.6068301225919439 0.5830740510267579\n",
      "3 21.791509926319122 0.626970227670753 0.6052686164696122\n",
      "4 20.53831309080124 0.6461179217746643 0.6185438705662726\n",
      "5 19.536734640598297 0.6614711033274956 0.6274631819124663\n",
      "6 18.686891198158264 0.6754816112084063 0.6353453640323584\n",
      "7 17.93681228160858 0.688733216579101 0.6465463596764157\n",
      "8 17.257445007562637 0.699883245767659 0.6538062642605269\n",
      "9 16.629733592271805 0.7128429655575015 0.6631404272972412\n",
      "10 16.038014620542526 0.7234676007005254 0.6708151835718731\n",
      "11 15.508488088846207 0.7300058377116171 0.6797344949180668\n",
      "12 15.255434840917587 0.7430239346176299 0.6842978635137938\n",
      "13 14.544320568442345 0.7536485697606539 0.6840904376685335\n",
      "14 14.012437254190445 0.7559252772913018 0.6826384567517113\n",
      "15 13.895058989524841 0.7646234676007005 0.6884463804190002\n",
      "16 13.057566717267036 0.7789842381786339 0.6971582659199336\n",
      "17 12.837895452976227 0.7865148861646235 0.7017216345156606\n",
      "18 12.278941452503204 0.7992994746059545 0.7037958929682638\n",
      "19 11.885385647416115 0.7978984238178634 0.7023439120514416\n",
      "20 11.508472636342049 0.8084646818447169 0.706492428956648\n",
      "21 10.83470007777214 0.8212492702860479 0.7112632233976354\n",
      "22 10.599565714597702 0.8244016345592527 0.7131300560049783\n",
      "23 10.048545613884926 0.839112667834209 0.7129226301597179\n",
      "24 9.970307469367981 0.8408639813193228 0.7156191661481021\n",
      "25 9.129361305385828 0.8589608873321658 0.7185231279817466\n",
      "26 8.70717715099454 0.8648569760653824 0.7199751088985687\n",
      "27 8.454612120985985 0.8554582603619382 0.7222567931964323\n",
      "28 8.19197240844369 0.8779334500875656 0.7195602572080482\n",
      "29 7.400291658937931 0.8828955049620548 0.7176934246007053\n",
      "30 7.536223143339157 0.900758902510216 0.72080481227961\n",
      "31 6.92215346544981 0.8939871570344425 0.7181082762912259\n",
      "32 6.3982736971229315 0.91138353765324 0.7222567931964323\n",
      "33 6.083949502557516 0.9157618213660245 0.7187305538270068\n",
      "34 5.653787557035685 0.9232340922358435 0.7235013482679942\n",
      "35 5.234124632552266 0.9335084646818447 0.7214270898153909\n",
      "36 4.878728926181793 0.9371278458844133 0.7247459033395561\n",
      "37 4.480972081422806 0.9461179217746644 0.7222567931964323\n",
      "38 4.178939160890877 0.9513134851138354 0.7272350134826799\n",
      "39 3.8034135345369577 0.9584354932866317 0.7218419415059116\n",
      "40 3.5279880547896028 0.9650321074138938 0.7235013482679942\n",
      "41 3.1979659739881754 0.9682428488032692 0.7230864965774736\n",
      "42 2.9490858037024736 0.9738470519556334 0.7224642190416926\n",
      "43 2.68457527179271 0.9762405137186223 0.7230864965774736\n",
      "44 2.468939053826034 0.9806771745475773 0.7222567931964323\n",
      "45 2.2633521794341505 0.9831873905429072 0.7226716448869529\n",
      "46 2.0809431676752865 0.9860478692352598 0.7218419415059116\n",
      "47 1.9126453674398363 0.9882661996497373 0.7218419415059116\n",
      "48 1.7594042592681944 0.9907764156450671 0.7226716448869529\n",
      "49 1.6199972643516958 0.9926444833625219 0.7214270898153909\n"
     ]
    }
   ],
   "source": [
    "model = FeedForwardTagger(vocab_size=len(word2idx_rand), \n",
    "                          window_size=1,\n",
    "                          output_dim=len(all_labels))\n",
    "_ = train_util(model, X_train_w1, Y_train, X_dev_w1, Y_dev, n_epochs=50,\n",
    "              lr=2, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 2\n",
    "X_train_w2 = encode_lines(train, word2idx_rand, window_size=2)\n",
    "X_dev_w2 = encode_lines(dev, word2idx_rand, window_size=2)\n",
    "X_devtest_w2 = encode_lines(devtest, word2idx_rand, window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2408864498138428 0.1950379451255108 0.18481642812694463\n",
      "1 3.0854387283325195 0.29422066549912435 0.2750466708151836\n",
      "2 2.9423320293426514 0.34098073555166375 0.3194358017008919\n",
      "3 2.8048031330108643 0.36065382370110916 0.34204521883426675\n",
      "4 2.674838066101074 0.3745475773496789 0.35573532462144786\n",
      "5 2.5570180416107178 0.39136018680677176 0.37295166977805433\n",
      "6 2.4515624046325684 0.40461179217746646 0.3887160340178386\n",
      "7 2.356186866760254 0.4204319906596614 0.4048952499481435\n",
      "8 2.2698733806610107 0.4332165791009924 0.4206596141879278\n",
      "9 2.192101001739502 0.4447752481027437 0.43808338518979467\n",
      "10 2.1223580837249756 0.4558085230589609 0.45218834266749636\n",
      "11 2.060042142868042 0.4649737302977233 0.4627670607757727\n",
      "12 2.0045011043548584 0.4740805604203152 0.4704418170504045\n",
      "13 1.9550763368606567 0.4807355516637478 0.4764571665629537\n",
      "14 1.9110753536224365 0.4871570344424985 0.4833022194565443\n",
      "15 1.8718129396438599 0.49281961471103325 0.4866210329807094\n",
      "16 1.8366429805755615 0.4995329830706363 0.49242895664799835\n",
      "17 1.8049681186676025 0.5042615294804437 0.4992740095415889\n",
      "18 1.776274561882019 0.5085230589608873 0.5034225264467953\n",
      "19 1.7501349449157715 0.5135434909515469 0.5067413399709604\n",
      "20 1.7261595726013184 0.5169293636894338 0.5113047085666874\n",
      "21 1.7040401697158813 0.520373613543491 0.5156606513171541\n",
      "22 1.6835383176803589 0.5245183887915937 0.5171126322339763\n",
      "23 1.6644045114517212 0.5276707530647986 0.5204314457581415\n",
      "24 1.6464587450027466 0.5311150029188558 0.5237502592823066\n",
      "25 1.629573941230774 0.5349678925861062 0.5283136278780336\n",
      "26 1.6135972738265991 0.5378283712784588 0.5308027380211574\n",
      "27 1.5984512567520142 0.5403969643899591 0.5320472930927194\n",
      "28 1.5840277671813965 0.5438412142440163 0.536403235843186\n",
      "29 1.5702626705169678 0.5467600700525395 0.5399294752126115\n",
      "30 1.557101845741272 0.549503794512551 0.5411740302841734\n",
      "31 1.544486165046692 0.5520723876240514 0.542211159510475\n",
      "32 1.5323783159255981 0.5549912434325744 0.5442854179630782\n",
      "33 1.5207315683364868 0.5572679509632225 0.546152250570421\n",
      "34 1.5095285177230835 0.560128429655575 0.5480190831777639\n",
      "35 1.498719573020935 0.5625802685347344 0.5507156191661481\n",
      "36 1.4882994890213013 0.5652656158785756 0.552582451773491\n",
      "37 1.4782286882400513 0.5677758318739055 0.5534121551545322\n",
      "38 1.468493938446045 0.5701692936368944 0.5540344326903132\n",
      "39 1.4590668678283691 0.5728546409807356 0.5561086911429164\n",
      "40 1.4499363899230957 0.5747227086981903 0.5585978012860402\n",
      "41 1.4410897493362427 0.5764740221833041 0.5598423563576022\n",
      "42 1.432494044303894 0.5793345008756567 0.5602572080481228\n",
      "43 1.4241474866867065 0.581260945709282 0.5619166148102054\n",
      "44 1.4160341024398804 0.583420899007589 0.5652354283343705\n",
      "45 1.408136010169983 0.5849387040280211 0.5660651317154117\n",
      "46 1.4004533290863037 0.587098657326328 0.5658577058701514\n",
      "47 1.39296293258667 0.5885580852305896 0.5671022609417133\n",
      "48 1.3856667280197144 0.590893169877408 0.5683468160132753\n",
      "49 1.3785545825958252 0.5928196147110333 0.5702136486206181\n",
      "50 1.3716071844100952 0.5952130764740222 0.5718730553827007\n",
      "51 1.3648245334625244 0.5968476357267951 0.5722879070732213\n",
      "52 1.3581992387771606 0.5986573263280794 0.572702758763742\n",
      "53 1.3517261743545532 0.5998248686514887 0.5743621655258245\n",
      "54 1.3453941345214844 0.6018680677174547 0.5751918689068658\n",
      "55 1.3391950130462646 0.6032691185055459 0.5768512756689483\n",
      "56 1.3331378698349 0.6054290718038529 0.5791329599668119\n",
      "57 1.3272031545639038 0.6070052539404553 0.5805849408836341\n",
      "58 1.3213846683502197 0.6088149445417397 0.5818294959551961\n",
      "59 1.3156956434249878 0.610507880910683 0.582451773490977\n",
      "60 1.3101074695587158 0.611908931698774 0.5845260319435802\n",
      "61 1.3046245574951172 0.6141272621132516 0.5857705870151421\n",
      "62 1.299250841140747 0.6159953298307064 0.5874299937772246\n",
      "63 1.2939770221710205 0.6172796263864565 0.5880522713130056\n",
      "64 1.2887969017028809 0.6183887915936953 0.5899191039203485\n",
      "65 1.2837164402008057 0.6199065966141273 0.5911636589919104\n",
      "66 1.2787219285964966 0.6213660245183887 0.5930304915992533\n",
      "67 1.2738080024719238 0.622650321074139 0.5944824725160756\n",
      "68 1.2689850330352783 0.6235843549328663 0.5957270275876374\n",
      "69 1.2642390727996826 0.6248686514886165 0.5969715826591994\n",
      "70 1.2595689296722412 0.6260361938120257 0.5988384152665422\n",
      "71 1.2549785375595093 0.6272621132516054 0.6002903961833644\n",
      "72 1.2504554986953735 0.6292469352014011 0.6009126737191454\n",
      "73 1.2460098266601562 0.630881494454174 0.6011200995644057\n",
      "74 1.2416226863861084 0.6323409223584355 0.6021572287907073\n",
      "75 1.2373080253601074 0.6336252189141857 0.6038166355527899\n",
      "76 1.2330539226531982 0.6347343841214244 0.6056834681601327\n",
      "77 1.228865146636963 0.6352597781669586 0.6063057456959137\n",
      "78 1.2247339487075806 0.6363105662580268 0.6069280232316947\n",
      "79 1.2206602096557617 0.637594862813777 0.607757726612736\n",
      "80 1.216641902923584 0.6386456509048453 0.6092097075295582\n",
      "81 1.2126808166503906 0.639871570344425 0.6104542626011201\n",
      "82 1.2087804079055786 0.640630472854641 0.6106616884463805\n",
      "83 1.2049211263656616 0.6417396380618797 0.6106616884463805\n",
      "84 1.2011213302612305 0.6424401634559253 0.6119062435179423\n",
      "85 1.197365164756775 0.6430239346176299 0.612321095208463\n",
      "86 1.193656325340271 0.6440163455925277 0.612321095208463\n",
      "87 1.190002202987671 0.6450087565674256 0.6121136693632027\n",
      "88 1.1863840818405151 0.6461179217746643 0.6133582244347646\n",
      "89 1.18281888961792 0.6467600700525394 0.6131507985895043\n",
      "90 1.1792950630187988 0.6476357267950963 0.6133582244347646\n",
      "91 1.175805687904358 0.6486281377699942 0.6135656502800249\n",
      "92 1.172373652458191 0.6492702860478692 0.6143953536610661\n",
      "93 1.1689748764038086 0.6501459427904261 0.6156399087326281\n",
      "94 1.1656107902526855 0.6511967308814944 0.6164696121136694\n",
      "95 1.162294864654541 0.6519556333917105 0.6172993154947106\n",
      "96 1.1590129137039185 0.6528896672504378 0.6179215930304915\n",
      "97 1.155771017074585 0.6538237011091652 0.6179215930304915\n",
      "98 1.1525604724884033 0.6545826036193813 0.6183364447210122\n",
      "99 1.1493936777114868 0.6552247518972563 0.6187512964115329\n",
      "100 1.1462600231170654 0.6559252772913018 0.6193735739473138\n",
      "101 1.1431626081466675 0.6572679509632224 0.6189587222567932\n",
      "102 1.1400952339172363 0.6581436077057793 0.6193735739473138\n",
      "103 1.1370630264282227 0.6589608873321658 0.6193735739473138\n",
      "104 1.1340620517730713 0.6601868067717455 0.6204107031736155\n",
      "105 1.1310938596725464 0.6607122008172797 0.6212404065546567\n",
      "106 1.1281588077545166 0.6609457092819615 0.6214478323999171\n",
      "107 1.1252601146697998 0.6615294804436661 0.6214478323999171\n",
      "108 1.122388243675232 0.6625802685347344 0.6218626840904377\n",
      "109 1.1195402145385742 0.6639813193228254 0.622070109935698\n",
      "110 1.116726279258728 0.6652656158785756 0.6224849616262186\n",
      "111 1.113940715789795 0.6657910099241098 0.6235220908525202\n",
      "112 1.111188292503357 0.6664331582019848 0.6245592200788218\n",
      "113 1.1084628105163574 0.6673088149445418 0.6247666459240822\n",
      "114 1.105758547782898 0.6680677174547577 0.6255963493051234\n",
      "115 1.1030832529067993 0.6685347343841215 0.626633478531425\n",
      "116 1.1004410982131958 0.6694103911266783 0.626633478531425\n",
      "117 1.0978199243545532 0.6699357851722125 0.627255756067206\n",
      "118 1.0952227115631104 0.6708698190309399 0.6274631819124663\n",
      "119 1.092650055885315 0.67215411558669 0.6278780336029869\n",
      "120 1.0901055335998535 0.6725627553998832 0.6280854594482472\n",
      "121 1.0875821113586426 0.6735551663747811 0.6287077369840283\n",
      "122 1.0850862264633179 0.6740221833041448 0.6287077369840283\n",
      "123 1.0826098918914795 0.675189725627554 0.6291225886745488\n",
      "124 1.080156922340393 0.6755983654407473 0.6301597179008505\n",
      "125 1.0777240991592407 0.6762405137186223 0.6309894212818917\n",
      "126 1.0753155946731567 0.6766491535318155 0.631819124662933\n",
      "127 1.0729293823242188 0.6772329246935201 0.631819124662933\n",
      "128 1.070565104484558 0.678225335668418 0.6326488280439743\n",
      "129 1.0682216882705688 0.678867483946293 0.6338933831155362\n",
      "130 1.0658949613571167 0.6796847635726795 0.6349305123418378\n",
      "131 1.0635873079299927 0.6803269118505546 0.6361750674133997\n",
      "132 1.0612982511520386 0.6807939287799183 0.6357602157228791\n",
      "133 1.0590323209762573 0.6817863397548161 0.6367973449491807\n",
      "134 1.0567814111709595 0.6821949795680093 0.6372121966397013\n",
      "135 1.0545530319213867 0.6824284880326912 0.6372121966397013\n",
      "136 1.0523383617401123 0.6829538820782254 0.6380419000207426\n",
      "137 1.0501431226730347 0.68353765323993 0.6386641775565235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 1.0479636192321777 0.6842381786339755 0.6388716034017838\n",
      "139 1.0458006858825684 0.6851138353765324 0.6386641775565235\n",
      "140 1.043658971786499 0.6856392294220666 0.6386641775565235\n",
      "141 1.0415271520614624 0.6869819030939872 0.6386641775565235\n",
      "142 1.039417028427124 0.687215411558669 0.6384567517112633\n",
      "143 1.0373133420944214 0.6877991827203737 0.6388716034017838\n",
      "144 1.0352345705032349 0.6884997081144192 0.6386641775565235\n",
      "145 1.0331683158874512 0.6890251021599533 0.6386641775565235\n",
      "146 1.031112551689148 0.6892586106246351 0.6388716034017838\n",
      "147 1.0290756225585938 0.6899591360186806 0.6394938809375649\n",
      "148 1.0270510911941528 0.6905429071803852 0.6394938809375649\n",
      "149 1.0250391960144043 0.6911266783420899 0.6397013067828251\n",
      "150 1.0230484008789062 0.691768826619965 0.6394938809375649\n",
      "151 1.0210626125335693 0.6922358435493287 0.6394938809375649\n",
      "152 1.019087791442871 0.6926444833625219 0.6399087326280855\n",
      "153 1.017130970954895 0.6931115002918856 0.6399087326280855\n",
      "154 1.0151886940002441 0.6934617629889084 0.6407384360091267\n",
      "155 1.01325523853302 0.694045534150613 0.6413607135449076\n",
      "156 1.0113283395767212 0.6942790426152948 0.6417755652354283\n",
      "157 1.009419560432434 0.6945709281961471 0.6419829910806887\n",
      "158 1.0075228214263916 0.6956217162872154 0.6419829910806887\n",
      "159 1.0056358575820923 0.6963806187974314 0.6419829910806887\n",
      "160 1.0037630796432495 0.6970227670753065 0.6419829910806887\n",
      "161 1.0018988847732544 0.6976065382370111 0.641568139390168\n",
      "162 1.0000431537628174 0.6982486865148861 0.6417755652354283\n",
      "163 0.9982007145881653 0.6985405720957385 0.6423978427712093\n",
      "164 0.9963690042495728 0.6987740805604203 0.642190416925949\n",
      "165 0.994545042514801 0.699241097489784 0.6426052686164696\n",
      "166 0.992729902267456 0.699883245767659 0.6432275461522505\n",
      "167 0.9909253120422363 0.7004086398131932 0.6430201203069903\n",
      "168 0.9891371726989746 0.7008756567425569 0.6432275461522505\n",
      "169 0.98735111951828 0.7013426736719206 0.6436423978427712\n",
      "170 0.9855762720108032 0.7018680677174548 0.6436423978427712\n",
      "171 0.98381108045578 0.7023934617629889 0.6438498236880316\n",
      "172 0.9820560812950134 0.7029772329246935 0.6440572495332918\n",
      "173 0.9803084135055542 0.7033274956217163 0.6444721012238125\n",
      "174 0.9785648584365845 0.7039112667834209 0.6450943787595934\n",
      "175 0.9768386483192444 0.7043782837127845 0.6448869529143332\n",
      "176 0.9751140475273132 0.7048453006421482 0.6450943787595934\n",
      "177 0.9734016060829163 0.7050788091068301 0.6453018046048538\n",
      "178 0.9716979265213013 0.7054290718038528 0.6459240821406347\n",
      "179 0.9699912071228027 0.7058377116170461 0.6459240821406347\n",
      "180 0.9683006405830383 0.705954465849387 0.6465463596764157\n",
      "181 0.9666187763214111 0.7064798598949212 0.6463389338311554\n",
      "182 0.9649399518966675 0.7071803852889668 0.646753785521676\n",
      "183 0.9632753133773804 0.7075306479859895 0.6465463596764157\n",
      "184 0.9616135358810425 0.7078809106830123 0.6465463596764157\n",
      "185 0.9599589109420776 0.708231173380035 0.6469612113669363\n",
      "186 0.9583095908164978 0.7089316987740806 0.6479983405932379\n",
      "187 0.956672191619873 0.7091068301225919 0.6482057664384983\n",
      "188 0.9550387859344482 0.7094570928196147 0.6484131922837586\n",
      "189 0.9534085988998413 0.7096906012842965 0.6484131922837586\n",
      "190 0.9517899751663208 0.7103327495621716 0.6484131922837586\n",
      "191 0.9501721262931824 0.7103327495621716 0.6484131922837586\n",
      "192 0.9485641717910767 0.7107413893753649 0.6482057664384983\n",
      "193 0.9469621777534485 0.7110332749562172 0.6482057664384983\n",
      "194 0.945361316204071 0.7116754232340923 0.6484131922837586\n",
      "195 0.9437716007232666 0.7119089316987741 0.6488280439742792\n",
      "196 0.9421876072883606 0.7123175715119673 0.6490354698195395\n",
      "197 0.9406086802482605 0.712784588441331 0.6490354698195395\n",
      "198 0.9390358328819275 0.7128429655575015 0.6494503215100601\n",
      "199 0.9374639391899109 0.7132516053706947 0.6494503215100601\n",
      "200 0.9359033107757568 0.7136602451838879 0.6494503215100601\n",
      "201 0.9343502521514893 0.7138353765323993 0.6496577473553204\n",
      "202 0.9327972531318665 0.7140105078809107 0.6498651732005808\n",
      "203 0.931250810623169 0.7147694103911266 0.6498651732005808\n",
      "204 0.9297077655792236 0.7151196730881495 0.6504874507363617\n",
      "205 0.9281726479530334 0.7152948044366608 0.6502800248911015\n",
      "206 0.9266411662101746 0.7156450671336836 0.6504874507363617\n",
      "207 0.925113320350647 0.7158785755983654 0.6506948765816221\n",
      "208 0.9235891699790955 0.7166958552247519 0.6506948765816221\n",
      "209 0.9220741987228394 0.7171628721541156 0.6509023024268824\n",
      "210 0.9205591678619385 0.7178633975481611 0.6509023024268824\n",
      "211 0.9190521836280823 0.7185055458260362 0.651317154117403\n",
      "212 0.9175456762313843 0.7191476941039112 0.6515245799626633\n",
      "213 0.9160471558570862 0.7197314652656159 0.6515245799626633\n",
      "214 0.9145512580871582 0.7204903677758319 0.6515245799626633\n",
      "215 0.9130573868751526 0.7210157618213661 0.6517320058079237\n",
      "216 0.9115716814994812 0.7214244016345592 0.652561709188965\n",
      "217 0.9100865125656128 0.7222416812609457 0.652561709188965\n",
      "218 0.9086105823516846 0.7224168126094571 0.652561709188965\n",
      "219 0.9071336388587952 0.7227670753064799 0.6527691350342253\n",
      "220 0.9056627154350281 0.7234092235843549 0.652561709188965\n",
      "221 0.9041950106620789 0.7238178633975482 0.6527691350342253\n",
      "222 0.9027295708656311 0.7238178633975482 0.6531839867247459\n",
      "223 0.9012693166732788 0.7246935201401051 0.6535988384152666\n",
      "224 0.8998146653175354 0.7249854057209574 0.6540136901057871\n",
      "225 0.8983591198921204 0.7252189141856392 0.6544285417963078\n",
      "226 0.8969123363494873 0.7256859311150029 0.6544285417963078\n",
      "227 0.8954653143882751 0.7256859311150029 0.6540136901057871\n",
      "228 0.8940218687057495 0.7260361938120257 0.6538062642605269\n",
      "229 0.8925821781158447 0.7264448336252189 0.6535988384152666\n",
      "230 0.8911462426185608 0.7266783420899008 0.6535988384152666\n",
      "231 0.8897108435630798 0.7270286047869235 0.6535988384152666\n",
      "232 0.8882831335067749 0.7272621132516054 0.6540136901057871\n",
      "233 0.8868567943572998 0.7277291301809691 0.6544285417963078\n",
      "234 0.8854309320449829 0.7282545242265032 0.6544285417963078\n",
      "235 0.8840083479881287 0.7289550496205487 0.6548433934868284\n",
      "236 0.8825876712799072 0.7295971978984238 0.6546359676415682\n",
      "237 0.8811752796173096 0.7299474605954466 0.6556730968678698\n",
      "238 0.8797609806060791 0.730764740221833 0.6554656710226094\n",
      "239 0.8783533573150635 0.7312901342673672 0.6556730968678698\n",
      "240 0.8769448399543762 0.7316987740805604 0.65588052271313\n",
      "241 0.8755377531051636 0.732282545242265 0.65588052271313\n",
      "242 0.8741403222084045 0.7327495621716287 0.6560879485583904\n",
      "243 0.8727403879165649 0.7334500875656742 0.6562953744036507\n",
      "244 0.8713457584381104 0.7335668417980151 0.6565028002489111\n",
      "245 0.8699510097503662 0.7339754816112084 0.6565028002489111\n",
      "246 0.8685557842254639 0.7343841214244017 0.6565028002489111\n",
      "247 0.8671691417694092 0.7346760070052539 0.6565028002489111\n",
      "248 0.8657811880111694 0.7350846468184472 0.6567102260941713\n",
      "249 0.8643988370895386 0.735318155283129 0.6575399294752126\n",
      "250 0.8630135655403137 0.7354932866316404 0.6575399294752126\n",
      "251 0.8616364598274231 0.7361938120256859 0.6579547811657332\n",
      "252 0.8602563738822937 0.7366608289550496 0.6577473553204729\n",
      "253 0.8588810563087463 0.7370110916520723 0.6575399294752126\n",
      "254 0.8575095534324646 0.7373029772329247 0.6579547811657332\n",
      "255 0.8561385869979858 0.7377699941622884 0.6583696328562539\n",
      "256 0.8547657132148743 0.7384121424401635 0.6585770587015142\n",
      "257 0.8533983826637268 0.7388207822533567 0.6585770587015142\n",
      "258 0.852035403251648 0.7390542907180385 0.6589919103920349\n",
      "259 0.8506739735603333 0.7394629305312318 0.6591993362372952\n",
      "260 0.849308967590332 0.7399299474605955 0.6594067620825554\n",
      "261 0.8479496836662292 0.7402802101576182 0.6594067620825554\n",
      "262 0.8465930223464966 0.7405720957384705 0.6600290396183365\n",
      "263 0.8452377319335938 0.7407472270869819 0.6598216137730761\n",
      "264 0.8438766002655029 0.7410391126678342 0.6604438913088571\n",
      "265 0.8425256013870239 0.7416228838295388 0.6604438913088571\n",
      "266 0.8411766290664673 0.7422066549912434 0.6606513171541174\n",
      "267 0.8398260474205017 0.742790426152948 0.6606513171541174\n",
      "268 0.8384782671928406 0.7434325744308231 0.6606513171541174\n",
      "269 0.8371279835700989 0.7439579684763573 0.6608587429993777\n",
      "270 0.835780680179596 0.7444833625218914 0.6608587429993777\n",
      "271 0.8344367146492004 0.7450087565674256 0.6610661688446381\n",
      "272 0.8330990076065063 0.7455341506129597 0.6612735946898983\n",
      "273 0.8317544460296631 0.7457676590776415 0.6612735946898983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 0.830418586730957 0.7461762988908348 0.6618958722256794\n",
      "275 0.8290773630142212 0.7464681844716871 0.6618958722256794\n",
      "276 0.8277413249015808 0.746584938704028 0.6623107239161999\n",
      "277 0.8264058232307434 0.7470519556333917 0.6623107239161999\n",
      "278 0.8250706791877747 0.7472854640980735 0.6625181497614603\n",
      "279 0.8237396478652954 0.7476357267950963 0.6625181497614603\n",
      "280 0.8224065899848938 0.7480443666082895 0.6633478531425016\n",
      "281 0.8210771083831787 0.7482778750729714 0.6637627048330222\n",
      "282 0.8197477459907532 0.7487448920023351 0.6639701306782825\n",
      "283 0.8184197545051575 0.7491535318155284 0.6639701306782825\n",
      "284 0.8170944452285767 0.749737302977233 0.6635552789877619\n",
      "285 0.8157685399055481 0.7503210741389376 0.6635552789877619\n",
      "286 0.8144422173500061 0.7507880910683012 0.6637627048330222\n",
      "287 0.8131142854690552 0.7512551079976649 0.6643849823688032\n",
      "288 0.8117927312850952 0.7514302393461763 0.6645924082140635\n",
      "289 0.8104709982872009 0.7518972562755399 0.6645924082140635\n",
      "290 0.8091483116149902 0.7524226503210741 0.6647998340593237\n",
      "291 0.8078296184539795 0.7527729130180969 0.6652146857498444\n",
      "292 0.8065056800842285 0.7534734384121424 0.6654221115951048\n",
      "293 0.8051872849464417 0.7537069468768243 0.665629537440365\n",
      "294 0.8038705587387085 0.754057209573847 0.666251814976146\n",
      "295 0.8025503158569336 0.7544074722708698 0.666251814976146\n",
      "296 0.8012335300445557 0.7546993578517222 0.666251814976146\n",
      "297 0.7999147176742554 0.7551079976649153 0.666251814976146\n",
      "298 0.798600435256958 0.755575014594279 0.666251814976146\n",
      "299 0.7972833514213562 0.7559252772913018 0.6660443891308857\n",
      "300 0.7959718108177185 0.756333917104495 0.6660443891308857\n",
      "301 0.794657826423645 0.7565090484530064 0.6658369632856254\n",
      "302 0.7933462262153625 0.757209573847052 0.6660443891308857\n",
      "303 0.7920308709144592 0.7576765907764157 0.6664592408214064\n",
      "304 0.7907167673110962 0.7582603619381203 0.6664592408214064\n",
      "305 0.7894073724746704 0.7589025102159953 0.6670815183571873\n",
      "306 0.7880950570106506 0.759369527145359 0.6677037958929682\n",
      "307 0.7867847084999084 0.7600116754232341 0.6679112217382286\n",
      "308 0.7854762077331543 0.7605370694687682 0.6677037958929682\n",
      "309 0.7841636538505554 0.7609457092819615 0.6674963700477079\n",
      "310 0.7828532457351685 0.7612375948628137 0.6674963700477079\n",
      "311 0.7815472483634949 0.7615294804436661 0.6679112217382286\n",
      "312 0.7802387475967407 0.7621716287215412 0.6679112217382286\n",
      "313 0.7789301872253418 0.7625802685347344 0.6681186475834889\n",
      "314 0.7776184678077698 0.7630472854640981 0.6683260734287492\n",
      "315 0.7763128876686096 0.7638061879743141 0.6687409251192699\n",
      "316 0.7750065922737122 0.7641564506713369 0.6691557768097905\n",
      "317 0.7736973762512207 0.7644483362521891 0.6693632026550508\n",
      "318 0.7723900079727173 0.7648569760653824 0.6693632026550508\n",
      "319 0.771084189414978 0.7655575014594279 0.6697780543455715\n",
      "320 0.7697780132293701 0.7660245183887916 0.6697780543455715\n",
      "321 0.7684714198112488 0.7664331582019849 0.6699854801908318\n",
      "322 0.7671670317649841 0.7670169293636895 0.6704003318813524\n",
      "323 0.7658602595329285 0.7673088149445417 0.6710226094171333\n",
      "324 0.7645508646965027 0.7677758318739054 0.6710226094171333\n",
      "325 0.7632481455802917 0.76835960303561 0.6712300352623937\n",
      "326 0.7619406580924988 0.7688849970811442 0.6708151835718731\n",
      "327 0.7606340050697327 0.7692936368943374 0.6706077577266127\n",
      "328 0.7593289017677307 0.7698190309398716 0.6710226094171333\n",
      "329 0.7580246329307556 0.7702860478692353 0.6712300352623937\n",
      "330 0.7567131519317627 0.770636310566258 0.671437461107654\n",
      "331 0.75541090965271 0.7711033274956217 0.671437461107654\n",
      "332 0.7541048526763916 0.771511967308815 0.6718523127981747\n",
      "333 0.7527967095375061 0.7715703444249854 0.6716448869529144\n",
      "334 0.7514945268630981 0.7719789842381787 0.6716448869529144\n",
      "335 0.750184178352356 0.7722708698190309 0.671437461107654\n",
      "336 0.7488787770271301 0.7727962638645651 0.6718523127981747\n",
      "337 0.7475749254226685 0.7732632807939288 0.6722671644886953\n",
      "338 0.7462655305862427 0.7739638061879743 0.6720597386434349\n",
      "339 0.7449596524238586 0.7741389375364857 0.6722671644886953\n",
      "340 0.7436556816101074 0.7749562171628721 0.6722671644886953\n",
      "341 0.7423454523086548 0.7753648569760654 0.6722671644886953\n",
      "342 0.7410374879837036 0.7760653823701109 0.6722671644886953\n",
      "343 0.7397300004959106 0.7764156450671337 0.6722671644886953\n",
      "344 0.738422155380249 0.7766491535318155 0.6720597386434349\n",
      "345 0.7371156215667725 0.7774080560420316 0.6720597386434349\n",
      "346 0.7358067035675049 0.7778750729713952 0.6720597386434349\n",
      "347 0.7344973683357239 0.778225335668418 0.6716448869529144\n",
      "348 0.7331877946853638 0.7786923525977817 0.6718523127981747\n",
      "349 0.7318823337554932 0.7791009924109749 0.6718523127981747\n",
      "350 0.7305704951286316 0.7798015178050204 0.6718523127981747\n",
      "351 0.72925865650177 0.7806771745475773 0.6722671644886953\n",
      "352 0.7279501557350159 0.7809106830122592 0.6720597386434349\n",
      "353 0.7266407608985901 0.7812025685931115 0.672682016179216\n",
      "354 0.7253298759460449 0.7816112084063047 0.672682016179216\n",
      "355 0.7240187525749207 0.7823701109165208 0.6728894420244762\n",
      "356 0.7227047681808472 0.7831290134267367 0.6728894420244762\n",
      "357 0.7213969230651855 0.78353765323993 0.6728894420244762\n",
      "358 0.7200839519500732 0.7844133099824868 0.6735117195602572\n",
      "359 0.7187709212303162 0.7847635726795096 0.6735117195602572\n",
      "360 0.7174574136734009 0.7851138353765325 0.6739265712507778\n",
      "361 0.7161483764648438 0.7854640980735552 0.6733042937149969\n",
      "362 0.7148330807685852 0.7865148861646235 0.6733042937149969\n",
      "363 0.7135199308395386 0.7868651488616463 0.6737191454055175\n",
      "364 0.7122061848640442 0.7872737886748394 0.6739265712507778\n",
      "365 0.7108920812606812 0.787857559836544 0.6739265712507778\n",
      "366 0.7095745801925659 0.7882661996497373 0.6741339970960382\n",
      "367 0.7082574963569641 0.7886164623467601 0.6739265712507778\n",
      "368 0.7069449424743652 0.7890251021599533 0.6739265712507778\n",
      "369 0.7056278586387634 0.7893169877408056 0.6743414229412985\n",
      "370 0.7043102383613586 0.7897840046701693 0.6743414229412985\n",
      "371 0.7029930353164673 0.790251021599533 0.6747562746318191\n",
      "372 0.7016782760620117 0.7904845300642148 0.6747562746318191\n",
      "373 0.7003551721572876 0.7913601868067718 0.6749637004770794\n",
      "374 0.699038565158844 0.7918855808523059 0.6749637004770794\n",
      "375 0.6977178454399109 0.7924109748978401 0.6751711263223398\n",
      "376 0.696398138999939 0.7929947460595447 0.6749637004770794\n",
      "377 0.6950790286064148 0.7934033858727378 0.6749637004770794\n",
      "378 0.6937601566314697 0.7939871570344424 0.6747562746318191\n",
      "379 0.6924395561218262 0.7943374197314652 0.6751711263223398\n",
      "380 0.6911176443099976 0.7948628137769994 0.6751711263223398\n",
      "381 0.6897944808006287 0.7953298307063631 0.6753785521676001\n",
      "382 0.6884738206863403 0.795446584938704 0.6755859780128604\n",
      "383 0.6871483325958252 0.7957968476357268 0.6757934038581207\n",
      "384 0.6858268976211548 0.7962054874489201 0.6757934038581207\n",
      "385 0.6845003366470337 0.7966725043782837 0.676000829703381\n",
      "386 0.6831746101379395 0.7971978984238178 0.6764156813939017\n",
      "387 0.6818537712097168 0.7976649153531815 0.676623107239162\n",
      "388 0.6805282831192017 0.7982486865148861 0.676623107239162\n",
      "389 0.679200291633606 0.7988908347927612 0.6764156813939017\n",
      "390 0.6778717041015625 0.7991827203736136 0.6770379589296827\n",
      "391 0.6765479445457458 0.7994746059544658 0.6770379589296827\n",
      "392 0.6752199530601501 0.7998248686514886 0.6768305330844223\n",
      "393 0.6738921403884888 0.8002918855808523 0.6770379589296827\n",
      "394 0.6725605726242065 0.8009340338587274 0.6770379589296827\n",
      "395 0.6712321043014526 0.8013426736719206 0.677245384774943\n",
      "396 0.6699044704437256 0.8016345592527729 0.677245384774943\n",
      "397 0.6685757040977478 0.8021015761821366 0.6776602364654636\n",
      "398 0.6672440767288208 0.8029772329246935 0.6780750881559843\n",
      "399 0.665911853313446 0.8032107413893753 0.6782825140012445\n",
      "400 0.6645837426185608 0.803677758318739 0.6780750881559843\n",
      "401 0.663250744342804 0.8039696438995914 0.6778676623107239\n",
      "402 0.6619168519973755 0.8043199065966141 0.6776602364654636\n",
      "403 0.6605854034423828 0.8049036777583187 0.6778676623107239\n",
      "404 0.659251868724823 0.8054290718038529 0.6778676623107239\n",
      "405 0.6579197645187378 0.805954465849387 0.6778676623107239\n",
      "406 0.6565818190574646 0.8065382370110916 0.6778676623107239\n",
      "407 0.6552495956420898 0.8070636310566258 0.6778676623107239\n",
      "408 0.6539130806922913 0.8075890251021599 0.6776602364654636\n",
      "409 0.6525784134864807 0.8078809106830123 0.6780750881559843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 0.6512418985366821 0.8082895504962054 0.6776602364654636\n",
      "411 0.6499039530754089 0.8087565674255692 0.6778676623107239\n",
      "412 0.6485701203346252 0.8092819614711033 0.6780750881559843\n",
      "413 0.647233247756958 0.8101576182136603 0.6780750881559843\n",
      "414 0.6458925604820251 0.8106830122591944 0.677245384774943\n",
      "415 0.644554078578949 0.8109165207238762 0.6776602364654636\n",
      "416 0.6432172060012817 0.8113251605370695 0.6774528106202032\n",
      "417 0.6418792009353638 0.8117338003502627 0.6778676623107239\n",
      "418 0.6405388116836548 0.8119089316987741 0.6778676623107239\n",
      "419 0.639200747013092 0.8124927028604787 0.6776602364654636\n",
      "420 0.6378592252731323 0.8129597197898424 0.6776602364654636\n",
      "421 0.6365196704864502 0.8132516053706947 0.6778676623107239\n",
      "422 0.6351797580718994 0.8136018680677175 0.6789047915370255\n",
      "423 0.6338367462158203 0.8141856392294221 0.6789047915370255\n",
      "424 0.6324960589408875 0.8145942790426153 0.6782825140012445\n",
      "425 0.6311555504798889 0.8153531815528313 0.6782825140012445\n",
      "426 0.6298137307167053 0.8160537069468768 0.6786973656917652\n",
      "427 0.6284714937210083 0.8167542323409224 0.6789047915370255\n",
      "428 0.6271275281906128 0.8171628721541155 0.6789047915370255\n",
      "429 0.6257848143577576 0.8177466433158201 0.6789047915370255\n",
      "430 0.6244415044784546 0.8179801517805021 0.6791122173822859\n",
      "431 0.6230961680412292 0.8183304144775249 0.6791122173822859\n",
      "432 0.6217556595802307 0.8185639229422067 0.6789047915370255\n",
      "433 0.6204084753990173 0.8192644483362522 0.6789047915370255\n",
      "434 0.6190666556358337 0.8199065966141272 0.6789047915370255\n",
      "435 0.6177196502685547 0.8203736135434909 0.6786973656917652\n",
      "436 0.6163750290870667 0.8210741389375364 0.6786973656917652\n",
      "437 0.6150308847427368 0.8215995329830706 0.6784899398465049\n",
      "438 0.6136829853057861 0.8221249270286047 0.6784899398465049\n",
      "439 0.6123385429382324 0.8226503210741389 0.6780750881559843\n",
      "440 0.6109911799430847 0.8231757151196731 0.6780750881559843\n",
      "441 0.6096465587615967 0.8236427320490368 0.6782825140012445\n",
      "442 0.6082972288131714 0.8238762405137187 0.6782825140012445\n",
      "443 0.6069521307945251 0.8245183887915937 0.6784899398465049\n",
      "444 0.6056066155433655 0.8247518972562755 0.6784899398465049\n",
      "445 0.6042617559432983 0.824810274372446 0.6778676623107239\n",
      "446 0.6029136180877686 0.8253940455341506 0.6782825140012445\n",
      "447 0.6015647649765015 0.8256859311150029 0.6784899398465049\n",
      "448 0.6002181172370911 0.8264448336252189 0.6780750881559843\n",
      "449 0.5988699197769165 0.8268534734384121 0.6780750881559843\n",
      "450 0.5975254774093628 0.8273788674839463 0.6782825140012445\n",
      "451 0.5961763858795166 0.8280793928779918 0.6782825140012445\n",
      "452 0.5948297381401062 0.8284296555750146 0.6780750881559843\n",
      "453 0.5934823751449585 0.8288382953882079 0.6778676623107239\n",
      "454 0.5921362638473511 0.829246935201401 0.6776602364654636\n",
      "455 0.5907880663871765 0.8298307063631056 0.6774528106202032\n",
      "456 0.5894407629966736 0.8302393461762989 0.6776602364654636\n",
      "457 0.5880932807922363 0.8307063631056626 0.6776602364654636\n",
      "458 0.5867466926574707 0.8314652656158785 0.6778676623107239\n",
      "459 0.58539879322052 0.8320490367775832 0.6776602364654636\n",
      "460 0.5840510725975037 0.8323409223584355 0.6778676623107239\n",
      "461 0.5827018618583679 0.8327495621716288 0.6778676623107239\n",
      "462 0.5813561081886292 0.8332165791009924 0.6778676623107239\n",
      "463 0.5800105929374695 0.8336252189141856 0.6774528106202032\n",
      "464 0.5786664485931396 0.8340338587273789 0.6778676623107239\n",
      "465 0.577315628528595 0.8343257443082311 0.6784899398465049\n",
      "466 0.5759720206260681 0.8350262697022767 0.6780750881559843\n",
      "467 0.5746256709098816 0.83543490951547 0.6782825140012445\n",
      "468 0.5732797980308533 0.8360186806771746 0.6784899398465049\n",
      "469 0.5719324350357056 0.8366024518388792 0.6782825140012445\n",
      "470 0.5705868601799011 0.8368943374197315 0.6782825140012445\n",
      "471 0.5692420601844788 0.8375364856976065 0.6789047915370255\n",
      "472 0.5678967237472534 0.8376532399299474 0.6789047915370255\n",
      "473 0.5665517449378967 0.8384121424401635 0.6786973656917652\n",
      "474 0.5652092695236206 0.8386456509048453 0.6789047915370255\n",
      "475 0.563869833946228 0.8392877991827203 0.6789047915370255\n",
      "476 0.5625351071357727 0.8394629305312318 0.6789047915370255\n",
      "477 0.5612077713012695 0.840630472854641 0.6793196432275461\n",
      "478 0.5598964095115662 0.8402802101576182 0.6793196432275461\n",
      "479 0.5586146116256714 0.8411558669001752 0.6797344949180668\n",
      "480 0.557376503944397 0.8417396380618798 0.6795270690728065\n",
      "481 0.556244969367981 0.8419731465265616 0.6803567724538477\n",
      "482 0.5552670359611511 0.8431990659661412 0.6789047915370255\n",
      "483 0.5546779632568359 0.8406888499708114 0.6813939016801493\n",
      "484 0.5545653104782104 0.8416812609457093 0.6786973656917652\n",
      "485 0.5559404492378235 0.8347927612375948 0.682431030906451\n",
      "486 0.5583862662315369 0.8333333333333334 0.6757934038581207\n",
      "487 0.5662454962730408 0.8220665499124343 0.6832607342874922\n",
      "488 0.572978675365448 0.8153531815528313 0.6689483509645302\n",
      "489 0.5952172875404358 0.8078809106830123 0.6795270690728065\n",
      "490 0.5945273637771606 0.800758902510216 0.6633478531425016\n",
      "491 0.6244599223136902 0.8062463514302394 0.6782825140012445\n",
      "492 0.5982171893119812 0.8040863981319323 0.6650072599045841\n",
      "493 0.6166358590126038 0.8108581436077058 0.6801493466085874\n",
      "494 0.588347315788269 0.8122008172796263 0.6664592408214064\n",
      "495 0.6005443930625916 0.8157618213660245 0.6813939016801493\n",
      "496 0.5789040923118591 0.8178633975481612 0.6720597386434349\n",
      "497 0.5892451405525208 0.8192060712200817 0.6809790499896287\n",
      "498 0.57204270362854 0.8210741389375364 0.672682016179216\n",
      "499 0.5813244581222534 0.8213660245183888 0.68180875337067\n"
     ]
    }
   ],
   "source": [
    "model = FeedForwardTagger(vocab_size=len(word2idx_rand), \n",
    "                          window_size=2,\n",
    "                          output_dim=len(all_labels))\n",
    "_ = train_util(model, X_train_w2, Y_train, X_dev_w2, Y_dev, n_epochs=500,\n",
    "              lr=1, batch_size=X_train_w2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct maps for pretrained word embs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
